# Patent RAG System

A comprehensive Retrieval-Augmented Generation (RAG) system for US Patent data, built with multi-GPU processing capabilities and support for both modern XML patents and historical PDF images.

## ğŸ¯ Overview

This system downloads, processes, and creates embeddings for US Patent data from the USPTO, enabling semantic search across millions of patent documents. It supports:

- **Patent Grant XML files** (2002-2025) - Full-text patent data
- **Patent Grant PDF Images** (1790-2002) - Historical patent documents
- **Multi-GPU processing** with 3x RTX 4090 support
- **Distributed processing** with checkpointing and resume capabilities

## ğŸ“Š Current Status

- âœ… **2.27+ million patent embeddings** processed and ready
- âœ… **Patent Grant XML files** (2002-2025): 1,259 files, 113 GB
- âœ… **Patent Grant PDF Images** (1790-2002): 108 files, 1 TB
- âœ… **RAG system ready** for semantic search applications

## ğŸ—ï¸ Architecture

### Data Pipeline
```
USPTO API â†’ Download Scripts â†’ XML Processing â†’ Embedding Generation â†’ RAG Index
```

### Key Components
- **Download Scripts**: Automated USPTO data retrieval
- **Processing Pipeline**: XML parsing and text extraction
- **Embedding Generation**: Sentence Transformers with GPU acceleration
- **Index Storage**: NumPy arrays and memory-mapped files

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- CUDA-capable GPUs (tested with RTX 4090)
- 4+ TB storage space
- USPTO API key

### Installation
```bash
# Clone repository
git clone git@github.com:danbroz/patents-rag.git
cd patents-rag

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install torch torchvision torchaudio
pip install sentence-transformers lxml requests numpy

# Optional: for 1790-2002 PDFs with no text layer (OCR)
# pip install pytesseract Pillow
# System: sudo apt install tesseract-ocr   # Linux

# Set up your USPTO API key (get one at https://developer.uspto.gov/)
cp .env-example .env
# Edit .env and set USPTO_API_KEY=your-actual-key
```

### Basic Usage

#### 1. Download Patent Data
```bash
# Download modern XML + historical PDF patents
python3 download.py
```

#### 2. Process and Build Embeddings

To build the full RAG index (1790â€“present), run:

```bash
python3 build.py
```

`build.py` automatically detects and processes whichever sources are present:

- `bulk/*.zip` (XML grants, 2002â€“present)
- `bulk-older/*.tar` (PDF grants, 1790â€“2002)

It builds **`patents-embeddings/index.faiss`** and **`patents-index/patent_titles.npy`**, then deletes processed `.zip`/`.tar` archives to save disk space.

The 1790â€“2002 pipeline uses PDF text extraction (PyMuPDF) and optional OCR (Tesseract) for image-only scans, so it is slower and noisier than the XML pipeline.

#### Incremental updates (XML-only)

To download only **newer** XML grant files since the last checkpoint, rebuild the FAISS index, and redeploy the MCP server:

```bash
python3 update.py
```

`update.py` reads `checkpoints/build-progress.txt` to find the latest processed `ipgYYMMDD.zip`/`pgYYMMDD.zip`, downloads newer XML files via `download.py`, then runs `build.py` and `deploy.py`.

## ğŸ”Œ MCP Server (Docker)

This repo includes a small **MCP HTTP/SSE server** that exposes a `patent_search` tool backed by your FAISS index.

### Build the index first
The MCP server requires:
- `patents-embeddings/index.faiss`
- `patents-index/patent_titles.npy`

Create them with:
```bash
python3 build.py
```

### Deploy locally with Docker
```bash
python3 deploy.py
```

- **SSE endpoint**: `http://localhost:9000/sse`
- The server will emit an `endpoint` SSE event telling the client where to POST MCP messages (usually `/messages/?session_id=...`).

### Configuration (env vars)
- `PORT` (default: `9000`)
- `FAISS_INDEX_PATH` (default: `patents-embeddings/index.faiss`)
- `TITLES_PATH` (default: `patents-index/patent_titles.npy`)
- `MODEL_NAME` (default: `sentence-transformers/all-MiniLM-L6-v2`)

#### 3. Use the RAG System
```python
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# Load the model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Load patent data
titles = np.load('patents-index/patent_titles.npy', allow_pickle=True)
index = faiss.read_index('patents-embeddings/index.faiss')

# Semantic search
query = "artificial intelligence machine learning"
q = model.encode([query]).astype('float32')

# Find similar patents (inner product; for normalized vectors this equals cosine similarity)
scores, ids = index.search(q, k=10)
top_indices = ids[0]
top_scores = scores[0]

for idx, score in zip(top_indices, top_scores):
    print(f"Patent: {titles[idx]}")
    print(f"Similarity: {score:.4f}")
```

## ğŸ“ Project Structure

```
patents-rag/
â”œâ”€â”€ download.py                 # Unified download: XML + older PDFs
â”œâ”€â”€ build.py                    # Unified build: zip/tar â†’ FAISS index + titles
â”œâ”€â”€ deploy.py                   # Python-only Docker deploy script for MCP server
â”œâ”€â”€ checkpoints/                # Progress tracking (build-progress.txt, build-progress-older.txt)
â”œâ”€â”€ bulk/                       # XML patent files (113+ GB)
â”œâ”€â”€ bulk-older/                 # PDF patent tarballs (1 TB)
â”œâ”€â”€ patents-index/              # Processed patent titles
â”œâ”€â”€ patents-embeddings/         # FAISS index (index.faiss) and temporary artifacts
â””â”€â”€ README.md                   # This file
```

## âš™ï¸ Configuration

### API key (`.env`)

The project uses a **USPTO API key** from environment variables. Keys are loaded from a `.env` file so you never commit secrets.

1. **Copy the example file and add your key:**
   ```bash
   cp .env-example .env
   ```
2. **Edit `.env`** and set your key:
   ```
   USPTO_API_KEY=your-uspto-api-key-here
   ```
3. Get a free key at [developer.uspto.gov](https://developer.uspto.gov/).

The `.env` file is gitignored. Scripts that call the USPTO API (`download_grants.py`, `download_older_grants.py`, `build_grants.py`, `build_grants_mp.py`) will exit with a clear error if `USPTO_API_KEY` is missing.

### Hardware Configuration
The system is optimized for:
- **3x RTX 4090 GPUs** with 24GB VRAM each
- **16 CPU threads** for parallel processing
- **Multi-GPU processing** with automatic load balancing

### Processing Options
- **Distributed Training**: Uses `torch.distributed` (may have NCCL issues)
- **Multiprocessing**: Uses `torch.multiprocessing` (recommended)
- **Single GPU**: Fallback to single GPU processing

## ğŸ”§ Advanced Usage

### Custom Date Ranges
Modify date ranges in download scripts:
```python
START_DATE = datetime.date(2020, 1, 1)
END_DATE = datetime.date(2024, 12, 31)
```

### Different Embedding Models
Change the model in build scripts:
```python
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
```

### Resume Processing
The system automatically resumes from checkpoints:
```bash
# XML pipeline progress
cat checkpoints/build-progress.txt
./launch_build_bulk.sh

# PDF (1790-2002) pipeline progress
cat checkpoints/build-progress-older.txt
python3 build_older_grants.py
```

## ğŸ“ˆ Performance

### Processing Speed
- **XML Processing**: ~1,000 patents/minute per GPU
- **Embedding Generation**: ~2,000 embeddings/minute per GPU
- **Total Processing Time**: ~2-3 hours for 2.27M patents

### Storage Requirements
- **Raw Data**: ~1.2 TB (XML + PDF files)
- **Processed Data**: ~3.5 GB (embeddings + titles)
- **Temporary Files**: ~50 GB during processing

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### NCCL Peer Access Errors
```bash
# Use multiprocessing instead of distributed training
./launch_build_mp.sh
```

#### CUDA Out of Memory
```python
# Reduce batch size in build scripts
BATCH_SIZE = 32  # Reduce from 64
```

#### Download Failures
```bash
# Resume downloads (automatic retry built-in)
python3 download_grants.py
```

### GPU Monitoring
```bash
# Monitor GPU usage
nvidia-smi -l 1

# Check process status
ps aux | grep python
```

## ğŸ“ Data Sources

- **USPTO Patent Grant XML**: https://api.uspto.gov/api/v1/datasets/products/ptgrxml
- **USPTO Patent Grant PDF**: https://api.uspto.gov/api/v1/datasets/products/ptgrmp2
- **Date Range**: 1790-2025 (comprehensive historical coverage)

## ğŸ¤ Contributing

This is a private repository. For contributions or questions, please contact the repository owner.

## ğŸ“„ License

Private repository - All rights reserved.

## ğŸ™ Acknowledgments

- **USPTO** for providing comprehensive patent data
- **Sentence Transformers** for embedding models
- **PyTorch** for GPU acceleration
- **NVIDIA** for RTX 4090 GPU support

---

**Last Updated**: September 2024  
**Total Patents Processed**: 2,274,031  
**System Status**: âœ… Ready for Production Use
